{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to download trading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config info\n",
    "\n",
    "# URL for GDAX API requests. Currently set to sandbox\n",
    "website = 'https://public.sandbox.gdax.com'\n",
    "rest_api = 'https://api-public.sandbox.gdax.com'\n",
    "websocket_feed = 'wss://ws-feed-public.sandbox.gdax.com'\n",
    "fix_api = 'https://fix-public.sandbox.gdax.com'\n",
    "\n",
    "# GDAX authentication credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# GDAX download functions\n",
    "\n",
    "def date_to_iso8601(date):\n",
    "    return '{year}-{month:02d}-{day:02d}T{hour:02d}:{minute:02d}:{second:02d}'.format(\n",
    "      year=date.year,\n",
    "      month=date.month,\n",
    "      day=date.day,\n",
    "      hour=date.hour,\n",
    "      minute=date.minute,\n",
    "      second=date.second)\n",
    "\n",
    "\n",
    "def request_trade_slice(product_id, start, end, granularity):\n",
    "    \"\"\"\n",
    "    Request function with error catching and management for server error responses\n",
    "    Response is in the format: [[time, low, high, open, close, volume], ...]\n",
    "    \"\"\"\n",
    "    # Allow 3 retries (we might get rate limited).\n",
    "    retries = 3\n",
    "    \n",
    "    # Change dates to iso8601 format as specified\n",
    "    iso_start = date_to_iso8601(start)\n",
    "    iso_end = date_to_iso8601(end)\n",
    "\n",
    "    # Set uri\n",
    "    uri = 'https://api.gdax.com/products/{currency_pair}/candles'.format(currency_pair=product_id)\n",
    "    \n",
    "    for retry_count in range(0, retries):\n",
    "        response = requests.get(uri, {\n",
    "          'start': iso_start,\n",
    "          'end': iso_end,\n",
    "          'granularity': granularity * 60 # Converting to seconds for API\n",
    "        })\n",
    "        if response.status_code != 200 or not len(response.json()):\n",
    "            if retry_count + 1 == retries:\n",
    "                raise Exception('Failed to get exchange data for ({}, {})! Error message: {}'.format(start, end, response.text))\n",
    "            else:\n",
    "                # Exponential back-off.\n",
    "                time.sleep(1.5 ** retry_count)\n",
    "        else:\n",
    "            # Sort the historic rates (in ascending order) based on the timestamp.\n",
    "            result = sorted(response.json(), key=lambda x: x[0])\n",
    "            return result\n",
    "\n",
    "        \n",
    "def request_order_book(product_id, level):\n",
    "    \"\"\"\n",
    "    Returns the current order book for a currency pair. \n",
    "    :Level: Granularity level 1, 2, or 3 as defined by API. Default = 1, preferred for my usage is 2.\n",
    "    Level 2 response example: \n",
    "    {\n",
    "        \"sequence\": \"3\",\n",
    "        \"bids\": [\n",
    "            [ price, size, num-orders ],\n",
    "            [ \"295.96\", \"4.39088265\", 2 ],\n",
    "            ...\n",
    "        ],\n",
    "        \"asks\": [\n",
    "            [ price, size, num-orders ],\n",
    "            [ \"295.97\", \"25.23542881\", 12 ],\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Allow 3 retries (we might get rate limited).\n",
    "    retries = 3\n",
    "\n",
    "    # Set uri\n",
    "    uri = 'https://api.gdax.com/products/{currency_pair}/book'.format(currency_pair=product_id)\n",
    "    \n",
    "    for retry_count in range(0, retries):\n",
    "        response = requests.get(uri, {\n",
    "          'level': level\n",
    "        })\n",
    "        if response.status_code != 200 or not len(response.json()):\n",
    "            if retry_count + 1 == retries:\n",
    "                raise Exception('Failed to get order book data! Error message: {}'.format(response.text))\n",
    "            else:\n",
    "                # Exponential back-off.\n",
    "                time.sleep(1.5 ** retry_count)\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "        \n",
    "def gdax_trade_downloader(currency_pair, start, end, interval):\n",
    "    \"\"\"\n",
    "    Breaks up gdax trade data requests into chunks of 200 candlesticks to download in 1 second intervals, to comply with GDAX API rules\n",
    "    :currency_pair: string with requested crypto-fiat pair\n",
    "    :start: start of time period as datetime object\n",
    "    :end: end of time period as datetime object\n",
    "    :interval: candlestick intervals in ninutes\n",
    "    Returns an array with rows of candlestick data in the following format: [timestamp, low, high, open, close, volume]    \n",
    "    \"\"\"      \n",
    "    data = [] # Empty list to append data \n",
    "    delta = timedelta(minutes=interval * 200) # 200 intervals per request\n",
    "    slice_start = start\n",
    "    while slice_start != end:\n",
    "        slice_end = min(slice_start + delta, end)        \n",
    "        data += request_trade_slice(\n",
    "                product_id=currency_pair,\n",
    "                start=slice_start,\n",
    "                end=slice_end,\n",
    "                granularity=interval\n",
    "        )\n",
    "        slice_start = slice_end\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    data_frame = pandas.DataFrame(data=data, columns=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "    data_frame.set_index('time', inplace=True)\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "def gdax_order_book_downloader(currency_pair, interval, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Script to download order book at regular intervals. Will work out how to use this data with deep learning network later :)\n",
    "    :currency_pair: string with requested crypto-fiat pair\n",
    "    :interval: request intervals in minutes\n",
    "    :start_time: datetime object - the time at which this operation should start requesting data\n",
    "    :end_time: datetime object - the time at which this operation should finish\n",
    "    Returns something...\n",
    "    \"\"\"\n",
    "    data = [] # Empty list to append data\n",
    "    \n",
    "    # Calculate time to next interval\n",
    "    time_to_start =  min(start_time - datetime.datetime.now(),0) # Start when specified, or now if specified time is in the past\n",
    "    time.sleep(time_to_start)\n",
    "    \n",
    "    while datetime.datetime.now() < end_time:\n",
    "        data += request_order_book(\n",
    "                product_id=currency_pair,\n",
    "                level=2\n",
    "        )\n",
    "        time.sleep(interval*60) # sleep takes time in seconds\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    # Need to work out what I want to do with this. Order book has 2 pieces of important information. Presence of any walls, and overall size    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading for period of 2017-10-01 00:00:00 to 2017-10-01 16:40:00\n",
      "Downloading for period of 2017-10-01 16:40:00 to 2017-10-02 09:20:00\n",
      "Downloading for period of 2017-10-02 09:20:00 to 2017-10-03 02:00:00\n",
      "Downloading for period of 2017-10-03 02:00:00 to 2017-10-03 18:40:00\n",
      "Downloading for period of 2017-10-03 18:40:00 to 2017-10-04 11:20:00\n",
      "Downloading for period of 2017-10-04 11:20:00 to 2017-10-05 04:00:00\n",
      "Downloading for period of 2017-10-05 04:00:00 to 2017-10-05 20:40:00\n",
      "Downloading for period of 2017-10-05 20:40:00 to 2017-10-06 13:20:00\n",
      "Downloading for period of 2017-10-06 13:20:00 to 2017-10-07 06:00:00\n",
      "Downloading for period of 2017-10-07 06:00:00 to 2017-10-07 22:40:00\n",
      "Downloading for period of 2017-10-07 22:40:00 to 2017-10-08 15:20:00\n",
      "Downloading for period of 2017-10-08 15:20:00 to 2017-10-09 08:00:00\n",
      "Downloading for period of 2017-10-09 08:00:00 to 2017-10-10 00:40:00\n",
      "Downloading for period of 2017-10-10 00:40:00 to 2017-10-10 17:20:00\n",
      "Downloading for period of 2017-10-10 17:20:00 to 2017-10-11 10:00:00\n",
      "Downloading for period of 2017-10-11 10:00:00 to 2017-10-12 02:40:00\n",
      "Downloading for period of 2017-10-12 02:40:00 to 2017-10-12 19:20:00\n",
      "Downloading for period of 2017-10-12 19:20:00 to 2017-10-13 12:00:00\n",
      "Downloading for period of 2017-10-13 12:00:00 to 2017-10-14 04:40:00\n",
      "Downloading for period of 2017-10-14 04:40:00 to 2017-10-14 21:20:00\n",
      "Downloading for period of 2017-10-14 21:20:00 to 2017-10-15 14:00:00\n",
      "Downloading for period of 2017-10-15 14:00:00 to 2017-10-16 06:40:00\n",
      "Downloading for period of 2017-10-16 06:40:00 to 2017-10-16 23:20:00\n",
      "Downloading for period of 2017-10-16 23:20:00 to 2017-10-17 16:00:00\n",
      "Downloading for period of 2017-10-17 16:00:00 to 2017-10-18 08:40:00\n",
      "Downloading for period of 2017-10-18 08:40:00 to 2017-10-19 01:20:00\n",
      "Downloading for period of 2017-10-19 01:20:00 to 2017-10-19 18:00:00\n",
      "Downloading for period of 2017-10-19 18:00:00 to 2017-10-20 10:40:00\n",
      "Downloading for period of 2017-10-20 10:40:00 to 2017-10-21 03:20:00\n",
      "Downloading for period of 2017-10-21 03:20:00 to 2017-10-21 20:00:00\n",
      "Downloading for period of 2017-10-21 20:00:00 to 2017-10-22 12:40:00\n",
      "Downloading for period of 2017-10-22 12:40:00 to 2017-10-23 05:20:00\n",
      "Downloading for period of 2017-10-23 05:20:00 to 2017-10-23 22:00:00\n",
      "Downloading for period of 2017-10-23 22:00:00 to 2017-10-24 14:40:00\n",
      "Downloading for period of 2017-10-24 14:40:00 to 2017-10-25 07:20:00\n",
      "Downloading for period of 2017-10-25 07:20:00 to 2017-10-26 00:00:00\n",
      "Downloading for period of 2017-10-26 00:00:00 to 2017-10-26 16:40:00\n",
      "Downloading for period of 2017-10-26 16:40:00 to 2017-10-27 09:20:00\n",
      "Downloading for period of 2017-10-27 09:20:00 to 2017-10-28 02:00:00\n",
      "Downloading for period of 2017-10-28 02:00:00 to 2017-10-28 18:40:00\n",
      "Downloading for period of 2017-10-28 18:40:00 to 2017-10-29 11:20:00\n",
      "Downloading for period of 2017-10-29 11:20:00 to 2017-10-30 04:00:00\n",
      "Downloading for period of 2017-10-30 04:00:00 to 2017-10-30 20:40:00\n",
      "Downloading for period of 2017-10-30 20:40:00 to 2017-10-31 13:20:00\n",
      "Downloading for period of 2017-10-31 13:20:00 to 2017-11-01 06:00:00\n",
      "Downloading for period of 2017-11-01 06:00:00 to 2017-11-01 22:40:00\n",
      "Downloading for period of 2017-11-01 22:40:00 to 2017-11-02 15:20:00\n",
      "Downloading for period of 2017-11-02 15:20:00 to 2017-11-03 08:00:00\n",
      "Downloading for period of 2017-11-03 08:00:00 to 2017-11-04 00:40:00\n",
      "Downloading for period of 2017-11-04 00:40:00 to 2017-11-04 17:20:00\n",
      "Downloading for period of 2017-11-04 17:20:00 to 2017-11-05 10:00:00\n",
      "Downloading for period of 2017-11-05 10:00:00 to 2017-11-06 02:40:00\n",
      "Downloading for period of 2017-11-06 02:40:00 to 2017-11-06 19:20:00\n",
      "Downloading for period of 2017-11-06 19:20:00 to 2017-11-07 12:00:00\n",
      "Downloading for period of 2017-11-07 12:00:00 to 2017-11-08 04:40:00\n",
      "Downloading for period of 2017-11-08 04:40:00 to 2017-11-08 21:20:00\n",
      "Downloading for period of 2017-11-08 21:20:00 to 2017-11-09 14:00:00\n",
      "Downloading for period of 2017-11-09 14:00:00 to 2017-11-10 06:40:00\n",
      "Downloading for period of 2017-11-10 06:40:00 to 2017-11-10 23:20:00\n",
      "Downloading for period of 2017-11-10 23:20:00 to 2017-11-11 16:00:00\n",
      "Downloading for period of 2017-11-11 16:00:00 to 2017-11-12 08:40:00\n",
      "Downloading for period of 2017-11-12 08:40:00 to 2017-11-13 01:20:00\n",
      "Downloading for period of 2017-11-13 01:20:00 to 2017-11-13 18:00:00\n",
      "Downloading for period of 2017-11-13 18:00:00 to 2017-11-14 10:40:00\n",
      "Downloading for period of 2017-11-14 10:40:00 to 2017-11-15 03:20:00\n",
      "Downloading for period of 2017-11-15 03:20:00 to 2017-11-15 20:00:00\n",
      "Downloading for period of 2017-11-15 20:00:00 to 2017-11-16 12:40:00\n",
      "Downloading for period of 2017-11-16 12:40:00 to 2017-11-17 05:20:00\n",
      "Downloading for period of 2017-11-17 05:20:00 to 2017-11-17 22:00:00\n",
      "Downloading for period of 2017-11-17 22:00:00 to 2017-11-18 14:40:00\n",
      "Downloading for period of 2017-11-18 14:40:00 to 2017-11-19 07:20:00\n",
      "Downloading for period of 2017-11-19 07:20:00 to 2017-11-20 00:00:00\n",
      "Downloading for period of 2017-11-20 00:00:00 to 2017-11-20 16:40:00\n",
      "Downloading for period of 2017-11-20 16:40:00 to 2017-11-21 09:20:00\n",
      "Downloading for period of 2017-11-21 09:20:00 to 2017-11-22 02:00:00\n",
      "Downloading for period of 2017-11-22 02:00:00 to 2017-11-22 18:40:00\n",
      "Downloading for period of 2017-11-22 18:40:00 to 2017-11-23 11:20:00\n",
      "Downloading for period of 2017-11-23 11:20:00 to 2017-11-24 04:00:00\n",
      "Downloading for period of 2017-11-24 04:00:00 to 2017-11-24 20:40:00\n",
      "Downloading for period of 2017-11-24 20:40:00 to 2017-11-25 13:20:00\n",
      "Downloading for period of 2017-11-25 13:20:00 to 2017-11-26 06:00:00\n",
      "Downloading for period of 2017-11-26 06:00:00 to 2017-11-26 22:40:00\n",
      "Downloading for period of 2017-11-26 22:40:00 to 2017-11-27 15:20:00\n",
      "Downloading for period of 2017-11-27 15:20:00 to 2017-11-28 08:00:00\n",
      "Downloading for period of 2017-11-28 08:00:00 to 2017-11-29 00:40:00\n",
      "Downloading for period of 2017-11-29 00:40:00 to 2017-11-29 17:20:00\n",
      "Downloading for period of 2017-11-29 17:20:00 to 2017-11-30 10:00:00\n",
      "Downloading for period of 2017-11-30 10:00:00 to 2017-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "currency_pairs = ['ETH-USD',\n",
    "                 'ETH-EUR',\n",
    "                 'BTC-USD',\n",
    "                 'BTC-EUR',\n",
    "                 'LTC-USD',\n",
    "                 'LTC-EUR']\n",
    "\n",
    "start = datetime(2014,1,1)\n",
    "end = datetime(2017,12,31)\n",
    "\n",
    "for pair in currency_pairs:    \n",
    "    data =+ gdax_trade_downloader(pair, start, end, 5)\n",
    "    #panda data add column where all cell values are \"pair\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to download sentiment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate growth rates. Growth rate prediction is the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic RNN first\n",
    "#Then with multiple types of data, try a convnet + RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
