{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "sys.path.append('../..')\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, MaxPooling2D, Conv2D\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "from Classifier.data_processing import processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Initialise Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define prediction model\n",
    "class LSTM_net:\n",
    "    \"\"\"\n",
    "    RNN using LSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(LSTM(256, return_sequences=True,\n",
    "                       input_shape=self.input_size))  \n",
    "        #self.model.add(Dropout(0.2))\n",
    "        self.model.add(LSTM(256))  \n",
    "        #self.model.add(Dropout(0.2))\n",
    "        self.model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        # Define optimiser and compile\n",
    "        optimizer = optimizers.Adam(self.learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model\n",
    "sequence_length = 4\n",
    "input_size = 35\n",
    "learning_rate = 0.00001 # Only needed to define optimiser. Not used in prediction\n",
    "input_size = (sequence_length, input_size)\n",
    "LSTM_network = LSTM_net(input_size, learning_rate)\n",
    "\n",
    "# Load the model weights with the best validation loss.\n",
    "LSTM_network.model.load_weights('saved_models/LSTM_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load normalisation data\n",
    "with open('pickles/normalisation.pickle', 'rb') as f:\n",
    "    x_mean, x_std, y_mean, y_std = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data download and processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 1440 # 1440 minutes = 1 day\n",
    "\n",
    "def data_feed(interval, sequence_length, x_mean, x_std):\n",
    "    \"\"\"\n",
    "    Function to download most recent data, scrub and normalise it, and convert to sequential values for LSTM\n",
    "    :interval: Time period in minutes between datapoints. Needs to be same as for original training data\n",
    "    :sequence_length: Number of intervals of \"memory\" for LSTM network. Data will be fed in time windows of length=sequence_length\n",
    "    :x_mean: training/validation data mean values for normalisation\n",
    "    :x_std: training/validation data standard deviation values for normalisation\n",
    "    Returns tuple of np.array data for last time window. Shape of (1, sequence_length, input_size), and current price for logging purposes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download data for the most recent period\n",
    "    end_time = datetime.now().replace(microsecond=0,second=0,minute=0)\n",
    "    start_time = end_time - timedelta(minutes=interval * (sequence_length + 1)) # Adding some historical data in case interpolation needed\n",
    "    data = processor.historical_download(start_time, end_time, interval)\n",
    "    \n",
    "    # Convert to float and interpolate any missing values\n",
    "    data = data.astype('float64')\n",
    "    data = data.interpolate()\n",
    "    target = \"Btcusd_kraken_close\" # Only used for training. Must be the same as for training\n",
    "    current_price = data[target] # For logging purposes\n",
    "    \n",
    "    # Convert to growth rates and np.arrays\n",
    "    data = data.pct_change()\n",
    "    x = np.array(data[1:]) # First value removed. Will always be NaN because growth rates\n",
    "        \n",
    "    # Normalise data\n",
    "    x = (x - x_mean) / x_std\n",
    "    \n",
    "    # Reshape data from (num_samples, features) to (num_samples, sequence_length, features)\n",
    "    seq_x = []\n",
    "    for ii in range(len(x) - sequence_length + 1):\n",
    "        seq_x.append(x[ii : ii + sequence_length])\n",
    "    \n",
    "    seq_x = np.array(seq_x)\n",
    "    \n",
    "    input_data = np.reshape(seq_x[-1], (-1, sequence_length, seq_x.shape[2]))\n",
    "\n",
    "    return input_data, current_price[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trade scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_trading = False\n",
    "# Paper trading balances\n",
    "if not live_trading:\n",
    "    cash = 1000\n",
    "    btc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time period from 2018-03-14 02:36:24.003970 to 1521005107.9140759\n",
      "time period from 2018-03-14 12:25:07.914076 to 1521035506.7856727\n",
      "time period from 2018-03-14 20:51:46.785673 to 1521063034.0363095\n",
      "time period from 2018-03-15 04:30:34.036309 to 1521092498.1881964\n",
      "time period from 2018-03-15 12:41:38.188196 to 1521122946.0273845\n",
      "time period from 2018-03-15 21:09:06.027385 to 1521150701.0972052\n",
      "time period from 2018-03-16 04:51:41.097205 to 1521181300.0006766\n",
      "time period from 2018-03-16 13:21:40.000677 to 1521209692.0892293\n",
      "time period from 2018-03-16 21:14:52.089229 to 1521241702.7070386\n",
      "time period from 2018-03-17 06:08:22.707039 to 1521272636.5180721\n",
      "time period from 2018-03-17 14:43:56.518072 to 1521302217.4866335\n",
      "time period from 2018-03-17 22:56:57.486634 to 1521331815.3039234\n",
      "time period from 2018-03-18 07:10:15.303923 to 1521365452.2784066\n",
      "time period from 2018-03-18 16:30:52.278407 to 1521390652.0\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-18 23:30:52 to 1521415852.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alastairong/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 00:49:45.980301 to 1520990771.7059102\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 08:26:11.705910 to 1521019111.7258077\n",
      "time period from 2018-03-14 16:18:31.725808 to 1521045473.2742498\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 23:37:53.274250 to 1521073095.834538\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-15 07:18:15.834538 to 1521100893.640569\n",
      "time period from 2018-03-15 15:01:33.640569 to 1521126567.1723964\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-15 22:09:27.172396 to 1521154320.8622515\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-16 05:52:00.862252 to 1521182984.4422984\n",
      "time period from 2018-03-16 13:49:44.442298 to 1521209467.2305517\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-16 21:11:07.230552 to 1521239019.5946667\n",
      "time period from 2018-03-17 05:23:39.594667 to 1521269340.841495\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-17 13:49:00.841495 to 1521296637.5105765\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-17 21:23:57.510576 to 1521324187.851054\n",
      "time period from 2018-03-18 05:03:07.851054 to 1521352272.781746\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-18 12:51:12.781746 to 1521377472.0\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-18 19:51:12 to 1521402672.0\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 01:34:27.600196 to 1521001771.132274\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 11:29:31.132274 to 1521029074.6859095\n",
      "time period from 2018-03-14 19:04:34.685910 to 1521056931.7113502\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-15 02:48:51.711350 to 1521085113.8393676\n",
      "time period from 2018-03-15 10:38:33.839368 to 1521114599.2634964\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-15 18:49:59.263496 to 1521143918.1018167\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-16 02:58:38.101817 to 1521178251.1712775\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-16 12:30:51.171278 to 1521207012.941432\n",
      "time period from 2018-03-16 20:30:12.941432 to 1521237938.4519389\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-17 05:05:38.451939 to 1521276679.6649253\n",
      "time period from 2018-03-17 15:51:19.664925 to 1521305357.8997412\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-17 23:49:17.899741 to 1521332843.3649807\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-18 07:27:23.364981 to 1521364803.035321\n",
      "time period from 2018-03-18 16:20:03.035321 to 1521390003.0\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-18 23:20:03 to 1521415203.0\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 00:29:07.435853 to 1520988714.789617\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 07:51:54.789617 to 1521017692.9920764\n",
      "time period from 2018-03-14 15:54:52.992076 to 1521045369.6325514\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-14 23:36:09.632551 to 1521073541.977702\n",
      "time period from 2018-03-15 07:25:41.977702 to 1521100559.4780943\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-15 14:55:59.478094 to 1521126324.6866064\n",
      "time period from 2018-03-15 22:05:24.686606 to 1521154703.296329\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-16 05:58:23.296329 to 1521183343.944054\n",
      "call rate limiter exceeded (counter=21, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-16 13:55:43.944054 to 1521209636.1342654\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-16 21:13:56.134265 to 1521236592.7001956\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-17 04:43:12.700196 to 1521269329.805391\n",
      "time period from 2018-03-17 13:48:49.805391 to 1521296005.6496747\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-17 21:13:25.649675 to 1521321886.5411553\n",
      "time period from 2018-03-18 04:24:46.541155 to 1521350557.5456562\n",
      "call rate limiter exceeded (counter=20, limit=20) \n",
      " sleeping for 5 seconds\n",
      "time period from 2018-03-18 12:22:37.545656 to 1521375757.0\n",
      "time period from 2018-03-18 19:22:37 to 1521400957.0\n",
      "downloading ETH-USD data from 2018-03-13 17:00:00 to 2018-03-18 17:00:00\n",
      "downloading BTC-USD data from 2018-03-13 17:00:00 to 2018-03-18 17:00:00\n",
      "downloading BTC-EUR data from 2018-03-13 17:00:00 to 2018-03-18 17:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"trade (trigger: cron[day_of_week='mon-sun', hour='10', minute='13'], next run at: 2018-03-19 10:13:00 UTC)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/apscheduler/executors/base.py\", line 125, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "  File \"<ipython-input-7-8cc05f5b8c02>\", line 8, in trade\n",
      "    raw_prediction = LSTM_network.model.predict(input_data)\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 1025, in predict\n",
      "    steps=steps)\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1832, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1029, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2502, in function\n",
      "    return Function(inputs, outputs, updates=updates, **kwargs)\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2445, in __init__\n",
      "    with tf.control_dependencies(self.outputs):\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4746, in control_dependencies\n",
      "    return get_default_graph().control_dependencies(control_inputs)\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4446, in control_dependencies\n",
      "    c = self.as_graph_element(c)\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3459, in as_graph_element\n",
      "    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "  File \"/Users/alastairong/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3538, in _as_graph_element_locked\n",
      "    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\n",
      "ValueError: Tensor Tensor(\"dense_1/BiasAdd:0\", shape=(?, 1), dtype=float32) is not an element of this graph.\n"
     ]
    }
   ],
   "source": [
    "sched = BlockingScheduler()\n",
    "\n",
    "@sched.scheduled_job('cron', day_of_week='mon-sun', hour=10, minute=13, timezone='UTC')\n",
    "def trade():\n",
    "    # Run prediction script\n",
    "    Date = datetime.now()\n",
    "    input_data, current_price = data_feed(interval, sequence_length, x_mean, x_std)\n",
    "    raw_prediction = LSTM_network.model.predict(input_data)\n",
    "    expected_growth = raw_prediction.item() * y_std + y_mean\n",
    "    predicted_price = current_price * (1 + expected_growth)\n",
    "\n",
    "    # Simple trading algorithm.\n",
    "    if expected_growth > 0:\n",
    "        action = \"BUY\"\n",
    "        position += cash / test_actuals_for_seq[ii] * 0.997 # 0.997 to account for fees\n",
    "        cash = 0\n",
    "    if expected_growth < 0:\n",
    "        action = \"SELL\"\n",
    "        cash += position * test_actuals_for_seq[ii] * 0.997\n",
    "        position = 0\n",
    "\n",
    "    if live_trading:\n",
    "        # call Kraken API to make trades here\n",
    "        pass\n",
    "\n",
    "    # Reporting and logging\n",
    "    print(\"{}: {}. Price expected to change from {} to {}. Portfolio value of {}\".format(Date, action, current_price, predicted_price))    \n",
    "    log = pd.DataFrame([Date, action, current_price, predicted_price, cash, btc, (cash + btc * current_price)], columns=[\"Date\", \"Action\", \"Current Price\", \"Predicted_Price\", \"Cash_Position\", \"BTC_Position\", \"Portfolio_Value\"])\n",
    "    log.to_csv('trade_log.csv', encoding='utf-8', index=True)\n",
    "\n",
    "sched.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
